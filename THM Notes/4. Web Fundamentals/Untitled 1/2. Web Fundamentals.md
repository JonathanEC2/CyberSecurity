# Introduction to Web Hacking
## Exploring the Website

As a pen tester, your role when reviewing a website or web application is to discover features that could potentially be vulnerable and attempt to exploit them to assess whether or not they are. These features generally involve some interactivity with the user. 

Explore the website and note down the individual pages/areas/features with a summary for each one.

## Viewing the Page Source

The page source is the human-readable code returned to our browser/client from the web server each time we make a request.

- Always check for comments
- Explore all directories
- Check for clues of what web framework is being used. Knowing the framework and version can be a powerful find as there may be public vulnerabilities in the framework

## Developer Tools - Inspector

The page source doesn't always represent what's shown on a webpage. ; this is because CSS, JavaScript and user interaction can change the content and style of the page, which means we need a way to view what's been displayed in the browser window at this exact time. Element inspector assists us with this by providing us with a live representation of what is currently on the website.

## Developer Tools - Debugger

Called sources in Google Chrome

 Breakpoints are points in the code that we can force the browser to stop processing the JavaScript and pause the current execution. If you click the line number that contains the code, it creates a breakpoint.

## Developer Tools - Network

The network tab on the developer tools can be used to keep track of every external request a webpage makes. If you click on the Network tab and then refresh the page, you'll see all the files the page is requesting. 

AJAX is a method for sending and receiving network data in a web application background without interfering by changing the current web page.

# Content Discovery

When we talk about discovery, we are talking about the things that are not immediately presented to us and that weren't intended for us to have access to. This content could be, for example, pages or portals intended for staff usage, older versions of the website, backup files, configuration files, administration panels, etc.

There are three main ways of discovering content on a website:
- Manually
- Automated
- OSINT (Open-Source Intelligence)

## Manual Discover

#### Robots.txt

The robots.txt file is a document that tells search engines which pages they are and aren't allowed to show on their search engine results or ban specific search engines from crawling the website altogether. This file gives us a great list of locations on the website that the owners don't want us to discover as penetration testers.

#### Favicon

The favicon is a small icon displayed in the browser's address bar or tab used for branding a website. Sometimes when frameworks are used to build a website, a favicon that is part of the installation gets leftover, and if the website developer doesn't replace this with a custom one, this can give us a clue on what framework is in use.

#### Sitemap.xml

sitemap.xml file gives a list of every file the website owner wishes to be listed on a search engine. These can sometimes contain areas of the website that are a bit more difficult to navigate to or even list some old webpages that the current site no longer uses but are still working behind the scenes.

#### HTTP Headers

When we make requests to the web server, the server returns various HTTP headers. These headers can sometimes contain useful information such as the webserver software and possibly the programming/scripting language in use. Using this information, we could find vulnerable versions of software being used.

```
curl WEBPAGE_DOMAIN -v
```

#### Framework Stack

Once you've established the framework of a website, you can then locate the framework's website. From there, we can learn more about the software and other information, possibly leading to more content we can discover.

## OSINT

#### Google Hacking/Dorking

| **Filter** | **Example**        | **Description**                                              |
| ---------- | ------------------ | ------------------------------------------------------------ |
| site       | site:tryhackme.com | returns results only from the specified website address      |
| inurl      | inurl:admin        | returns results that have the specified word in the URL      |
| filetype   | filetype:pdf       | returns results which are a particular file extension        |
| intitle    | intitle:admin      | returns results that contain the specified word in the title |
#### Wappalyzer

Wappalyzer (https://www.wappalyzer.com/) is an online tool and browser extension that helps identify what technologies a website uses, such as frameworks, Content Management Systems (CMS), payment processors and much more

#### Wayback Machine

The Wayback Machine (https://archive.org/web/) is a historical archive of websites that dates back to the late 90s. You can search a domain name, and it will show you all the times the service scraped the web page and saved the contents. This service can help uncover old pages that may still be active on the current website.

#### GitHub

 Git is a version control system that tracks changes to files in a project. Working in a team is easier because you can see what each team member is editing and what changes they made to files. When users have finished making their changes, they commit them with a message and then push them back to a central location (repository) for the other users to then pull those changes to their local machines. You can use GitHub's search feature to look for company names or website names to try and locate repositories belonging to your target. Once discovered, you may have access to source code, passwords or other content that you hadn't yet found.

#### S3 Buckets

S3 Buckets are a storage service provided by Amazon AWS, allowing people to save files and even static website content in the cloud accessible over HTTP and HTTPS. Sometimes S3 bucket permissions are incorrectly set and inadvertently allow access to files that shouldn't be available to the public. The format of the S3 buckets is http(s)://{name}.s3.amazonaws.com where {name} is decided by the owner

## Automate Discovery 

```
ffuf -w /usr/share/wordlists/SecLists/Discovery/Web-Content/common.txt -u WEBSITE/FUZZ
```

```
dirb WEBSITE /usr/share/wordlists/SecLists/Discovery/Web-Content/common.txt
```

```
gobuster dir --url WEEBSITE -w /usr/share/wordlists/SecLists/Discovery/Web-Content/common.txt
```

Wordlist: https://github.com/danielmiessler/SecLists

# Subdomain Enumeration

Subdomain enumeration is the process of finding valid subdomains for a domain, but why do we do this. three different subdomain enumeration methods: 
- Brute Force
- OSINT (Open-Source Intelligence)
- Virtual Host.

## OSINT

#### SSL/TLS Certificates

When an SSL/TLS certificate is created for a domain by a CA (Certificate Authority), CA's take part in what's called "Certificate Transparency (CT) logs". These are publicly accessible logs of every SSL/TLS certificate created for a domain name. The purpose of Certificate Transparency logs is to stop malicious and accidentally made certificates from being used. We can use this service to our advantage to discover subdomains belonging to a domain, sites like https://crt.sh offer a searchable database of certificates that shows current and historical results.

#### Search Engines

Using advanced search methods on websites like Google, such as the <mark style="background: #D2B3FFA6;">site: filter</mark>, can narrow the search results. For example, <mark style="background: #D2B3FFA6;">site:*.domain.com -site:www.domain.com</mark> would only contain results leading to the domain name domain.com but exclude any links to www.domain.com; therefore, it shows us only subdomain names belonging to domain.com.

#### DNS Bruteforce

Bruteforce DNS (Domain Name System) enumeration is the method of trying tens, hundreds, thousands or even millions of different possible subdomains from a pre-defined list of commonly used subdomains. Because this method requires many requests, we automate it with tools to make the process quicker.

```
dnsrecon -t brt -d acmeitsupport.thm
```

```
./sublist3r.py -d acmeitsupport.thm
```

## Virtual Hosts
Some subdomains aren't always hosted in publically accessible DNS results, such as development versions of a web application or administration portals. Instead, the DNS record could be kept on a private DNS server or recorded on the developer's machines in their <span style="color:rgb(0, 176, 80)">/etc/hosts</span> file (or <span style="color:rgb(0, 176, 80)">c:\windows\system32\drivers\etc\hosts</span> file for Windows users), which maps domain names to IP addresses. 

Because web servers can host multiple websites from one server when a website is requested from a client, the server knows which website the client wants from the Host header. We can utilize this host header by making changes to it and monitoring the response to see if we've discovered a new website.


```
ffuf -w /usr/share/wordlists/SecLists/Discovery/DNS/namelist.txt -H "Host: FUZZ.acmeitsupport.thm" -u http://10.10.197.103
```

Because the above command will always produce a valid result, we need to filter the output. We can do this by using the page size result with the -fs switch. Edit the below command replacing {size} with the most occurring size value from the previous result

```
-w /usr/share/wordlists/SecLists/Discovery/DNS/namelist.txt -H "Host: FUZZ.acmeitsupport.thm" -u http://10.10.197.103 -fs {size}
```

# Authentication Bypass

## Username Enumeration

A helpful exercise to complete when trying to find authentication vulnerabilities is creating a list of valid usernames, which we'll use later in other tasks.

```
ffuf -w /usr/share/wordlists/SecLists/Usernames/Names/names.txt -X POST -d "username=FUZZ&email=x&password=x&cpassword=x" -H "Content-Type: application/x-www-form-urlencoded" -u http://10.10.16.45/customers/signup -mr "username already exists"
```

<span style="color:rgb(255, 192, 0)">-w</span> argument selects the file's location on the computer that contains the list of usernames
<span style="color:rgb(255, 192, 0)">-X</span> argument specifies the request method, this will be a GET request by default, but it is a POST request in our example
<span style="color:rgb(255, 192, 0)">-d</span> argument specifies the data that we are going to send
<span style="color:rgb(255, 192, 0)">-H</span> argument is used for adding additional headers to the request.<span style="color:rgb(255, 192, 0)">
</span> 
<span style="color:rgb(255, 192, 0)">-u</span> argument specifies the URL we are making the request to
<span style="color:rgb(255, 192, 0)">-mr</span> argument is the text on the page we are looking for to validate we've found a valid username.

**Output will be saved to file named valid_usernames.txt** 

## Brute Force

```
ffuf -w valid_usernames.txt:W1,/usr/share/wordlists/SecLists/Passwords/Common-Credentials/10-million-password-list-top-100.txt:W2 -X POST -d "username=W1&password=W2" -H "Content-Type: application/x-www-form-urlencoded" -u http://10.10.16.45/customers/login -fc 200
```

Because we're using multiple wordlists, we have to specify our own FUZZ keyword. In this instance, we've chosen W1 for our list of valid usernames and W2 for the list of passwords we will try. For a positive match, we're using the <span style="color:rgb(255, 192, 0)">-fc</span> argument to check for an HTTP status code other than 200.

## Logic Flaw

 A logic flaw is when the typical logical path of an application is either bypassed, circumvented or manipulated by a hacker. 

## Cookie Tampering

Examining and editing the cookies set by the web server during your online session can have multiple outcomes, such as unauthenticated access, access to another user's account, or elevated privileges.

### Encoding

 Encoding allows us to convert binary data into human-readable text that can be easily and safely transmitted over mediums that only support plain text ASCII characters.

# IDOR

IDOR (Insecure Direct Object Reference)  can occur when a web server receives user-supplied input to retrieve objects (files, data, documents), too much trust has been placed on the input data, and it is not validated on the server-side to confirm the requested object belongs to the user requesting it.

## Finding IDORs in Encoded IDs

When passing data from page to page either by post data,  web developers will often first take the raw data and encode it. Encoding ensures that the receiving web server will be able to understand the contents. The most common encoding technique on the web is base64 encoding and can usually be pretty easy to spot.

## Hashed IDs

Hashed IDs are a little bit more complicated, but they may follow a predictable pattern, such as being the hashed version of the integer value.

## Finding IDORs in Unpredictable IDs

If the Id cannot be detected using the above methods, an excellent method of IDOR detection is to create two accounts and swap the Id numbers between them. If you can view the other users' content using their Id number while still being logged in with a different account (or not logged in at all), you've found a valid IDOR vulnerability.

## A Practical IDOR Example

 You'll notice the username and email fields pre-filled in with your information. 

We'll start by investigating how this information gets pre-filled. If you open your browser developer tools, select the network tab and then refresh the page, you'll see a call to an endpoint with the path <span style="color:rgb(0, 176, 80)">/api/v1/customer?id={user_id}</span>. This page returns in JSON format your user id, username and email address. We can see from the path that the user information shown is taken from the query string's id parameter 

# File Inclusion

n some scenarios, web applications are written to request access to files on a given system, including images, static text, and so on via parameters. Parameters are query parameter strings attached to the URL that could be used to retrieve data or perform actions based on user input. 

![[../../../attachments/URL.png]]

For example, parameters are used with Google searching, where GET requests pass user input into the search engine.

File inclusion vulnerabilities are commonly found and exploited in various programming languages for web applications, such as PHP that are poorly written and implemented. The main issue of these vulnerabilities is the input validation, in which the user inputs are not sanitized or validated, and the user controls them. By default, an attacker can leverage file inclusion vulnerabilities to leak data, such as code, credentials or other important files related to the web application or operating system.

## Path Traversal

Also known as Directory traversal, a web security vulnerability allows an attacker to read operating system resources, such as local files on the server running an application. The attacker exploits this vulnerability by manipulating and abusing the web application's URL to locate and access files or directories stored outside the application's root directory.

Path traversal vulnerabilities occur when the user's input is passed to a function such as file_get_contents in PHP. 

 Path traversal attacks, also known as the dot-dot-slash attack, take advantage of moving the directory one step up using the double dots ../ .  If the attacker finds the entry point, which in this case get.php?file=, then the attacker may send something as follows, http://webapp.thm/get.php?file=../../../../etc/passwd

| **Location**                  | **Description**                                                                                                                                                   |
| ----------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `/etc/issue`                  | contains a message or system identification to be printed before the login prompt.                                                                                |
| `/etc/profile`                | controls system-wide default variables, such as Export variables, File creation mask (umask), Terminal types, Mail messages to indicate when new mail has arrived |
| `/proc/version`               | specifies the version of the Linux kernel                                                                                                                         |
| `etc/passwd`                  | has all registered users that have access to a system                                                                                                             |
| `/etc/shadow`                 | contains information about the system's users' passwords                                                                                                          |
| `/root/.bash_history`         | contains the history commands for `root` user                                                                                                                     |
| `/var/log/dmessage`           | contains global system messages, including the messages that are logged during system startup                                                                     |
| `/var/mail/root`              | all emails for `root` user                                                                                                                                        |
| `/root/.ssh/id_rsa`           | Private SSH keys for a root or any known valid user on the server                                                                                                 |
| `/var/log/apache2/access.log` | the accessed requests for `Apache` web server                                                                                                                     |
| `C:\boot.ini`                 | contains the boot options for computers with BIOS firmware                                                                                                        |

## Local File Inclusion - LFI

With PHP, using functions such as include, require, include_once, and require_once often contribute to vulnerable web applications.  LFI vulnerabilities also occur when using other languages such as ASP, JSP, or even in Node.js apps. LFI exploits follow the same concepts as path traversal.

Suppose the web application provides two languages, and the user can select between the EN and AR

```php
<?PHP 
	include($_GET["lang"]);
?>
```

The PHP code above uses a GET request via the URL parameter lang to include the file of the page. The call can be done by sending the following HTTP request as follows: http://webapp.thm/index.php?lang=EN.php to load the English page or http://webapp.thm/index.php?lang=AR.php to load the Arabic page, where EN.php and AR.php files exist in the same directory.

Theoretically, we can access and display any readable file on the server from the code above if there isn't any input validation. Let's say we want to read the /etc/passwd file, which contains sensitive information about the users of the Linux operating system, we can try the following: http://webapp.thm/get.php?file=THM-profile


```php
<?PHP 
	include("languages/". $_GET['lang']); 
?>
```

In the above code, the developer decided to use the include function to call PHP pages in the languages directory only via lang parameters. Again the payload looks similar to the path traversal, but the include function allows us to include any called files into the current page. The following will be the exploit:

http://webapp.thm/index.php?lang=../../../../etc/passwd

## Local File Inclusion - LFI #2


In this scenario, we have the following entry point: http://webapp.thm/index.php?lang=EN. If we enter an invalid input, such as THM, we get the following error


```php
Warning: include(languages/THM.php): failed to open stream: No such file or directory in /var/www/html/THM-4/index.php on line 12
```

We can tell the function includes files in the languages directory is adding .php at the end of the entry. Thus the valid input will be something as follows: index.php?lang=EN, where the file EN is located inside the given languages directory and named EN.php.

Also, the error message disclosed another important piece of information about the full web application directory path which is <span style="color:rgb(0, 176, 80)">/var/www/html/THM-4/</span> . To exploit this, we need to use the ../

Using null bytes is an injection technique where URL-encoded representation such as %00 or 0x00 in hex with user-supplied data to terminate strings. You could think of it as trying to trick the web app into disregarding whatever comes after the Null Byte.

**Note: the %00 trick is fixed and not working with PHP 5.3.4 and above.**

In the following scenarios, the developer starts to use input validation by filtering some keywords. Let's test out and check the error message!

http://webapp.thm/index.php?lang=../../../../etc/passwd

```php
Warning: include(languages/etc/passwd): failed to open stream: No such file or directory in /var/www/html/THM-5/index.php on line 15
```

If we check the warning message in the include(languages/etc/passwd) section, we know that the web application replaces the ../ with the empty string. 

First, we can send the following payload to bypass it: ....//....//....//....//....//etc/passwd. This works because the PHP filter only matches and replaces the first subset string ../

If developer forces the include to read from a defined directory, we need to include the directory in the payload like so:<mark style="background: #D2B3FFA6;"> ?lang=languages/../../../../../etc/passwd</mark>

## Remote File Inclusion - RFI